{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8e0f3a-eea1-4cf4-81e1-d9721276e5f3",
   "metadata": {},
   "source": [
    "# Dataset weights\n",
    "\n",
    "Notebook to get the weight of the different classes present in the dataset.\n",
    "\n",
    "This is computed only in the trainingset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b699a1a4-814f-4a43-ae2a-0b07cfb46c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warnings.py (30): You want to use `gym` which is not installed yet, install it with `pip install gym`.\n"
     ]
    }
   ],
   "source": [
    "from sflizard import LizardDataModule\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855f5368-57ca-44d8-aba8-a0e96194fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=540\n",
    "TRAIN_DATA_PATH=\"../data/Lizard_dataset_extraction/data_0.9_split_train.pkl\"\n",
    "VALID_DATA_PATH=\"../data/Lizard_dataset_extraction/data_0.9_split_valid.pkl\"\n",
    "TEST_DATA_PATH=\"../data/Lizard_dataset_extraction/data_0.9_split_test.pkl\"\n",
    "SEED=303\n",
    "BATCH_SIZE=4\n",
    "N_RAYS = 32\n",
    "\n",
    "ANNOTATION_TARGET = \"stardist_class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112f85e6-8096-4f4b-99e4-0881765a4259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 2976 examples\n"
     ]
    }
   ],
   "source": [
    "aditional_args={\"n_rays\":N_RAYS}\n",
    "\n",
    "# create the datamodule\n",
    "dm = LizardDataModule(\n",
    "    train_data_path=TRAIN_DATA_PATH,\n",
    "    valid_data_path=VALID_DATA_PATH,\n",
    "    test_data_path=TEST_DATA_PATH,\n",
    "    annotation_target=ANNOTATION_TARGET,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers = 1,\n",
    "    input_size=IMG_SIZE,\n",
    "    seed=SEED,\n",
    "    aditional_args=aditional_args,\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd87b71-65ba-4f0f-9b20-2c003f1c18e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744/744 [21:30<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "classes_representation = {}\n",
    "for i in range(7):\n",
    "    classes_representation[i] = 0\n",
    "train_iter = iter(dm.train_dataloader())\n",
    "for b in tqdm(range(len(train_iter))):\n",
    "    image, obj_probabilities, distances, classes = next(train_iter)\n",
    "    for i in range(len(image)):\n",
    "        class_map = torch.flatten(classes[i].int())\n",
    "        occurences = torch.bincount(class_map)\n",
    "        for o in range(len(occurences)):\n",
    "            classes_representation[o] += occurences[o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b41534-0d6a-4dc6-88c8-71c0c54229be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor(730841977), 1: tensor(1233446), 2: tensor(86053998), 3: tensor(15836149), 4: tensor(5157280), 5: tensor(1065106), 6: tensor(27613644)}\n"
     ]
    }
   ],
   "source": [
    "print(classes_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc09dddb-5101-4663-8941-e9fe629f1494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8421763419196278, 1: 0.0014213456163252062, 2: 0.09916321656931723, 3: 0.01824858239486998, 4: 0.005942925203180082, 5: 0.001227361184860687, 6: 0.03182022711181911}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for c in classes_representation.keys():\n",
    "    classes_representation[c] = classes_representation[c].item()\n",
    "    total += classes_representation[c]\n",
    "for c in classes_representation.keys():\n",
    "    classes_representation[c] /= total\n",
    "print(classes_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ba2e3d-f5eb-4de5-9356-55c4d4393212",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d779089-8d0f-438c-9c2e-8ee85bcd199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{0: 0.8435234983048621, 1: 0.0015844697497448515, 2: 0.09702835179125052, 3: 0.018770678077839286, 4: 0.005716505874930195, 5: 0.0011799091886332306, 6: 0.03219658701273987}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97847a6b",
   "metadata": {},
   "source": [
    "## HoverNet Graph class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf42fc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2976it [10:25,  4.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "\n",
    "true_dir = \"../data/Lizard_dataset_split/patches/Lizard_Labels_train/\"\n",
    "\n",
    "file_list = glob.glob(\"%s/*mat\" % (true_dir))\n",
    "\n",
    "classes = {}\n",
    "for i in range(7):\n",
    "    classes[i] = 0\n",
    "for idx, file in tqdm(enumerate(file_list)):\n",
    "    mat = sio.loadmat(file)\n",
    "    for i in range(len(mat[\"classes\"])):\n",
    "        classes[mat[\"classes\"][i][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4255506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.0\n",
      "1: 0.0015289419440833998\n",
      "2: 3.543263598039262e-05\n",
      "3: 7.946214852753756e-05\n",
      "4: 0.0002770799022561251\n",
      "5: 0.0021221063687575435\n",
      "6: 7.437612919581149e-05\n"
     ]
    }
   ],
   "source": [
    "class_bp = classes.copy()\n",
    "\n",
    "sum_c = sum(classes.values())\n",
    "for k, v in classes.items():\n",
    "    if k == 0:\n",
    "        classes[k] = 0\n",
    "    else:\n",
    "        classes[k] = 1/(v/sum_c)\n",
    "\n",
    "sum_c = sum(classes.values())\n",
    "for k, v in classes.items():\n",
    "    classes[k] = v/sum_c\n",
    "\n",
    "for k, v in classes.items():\n",
    "    print(f\"{k}: {(v/sum_c)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fa1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.0\n",
      "1: 0.3713368309107073\n",
      "2: 0.008605586894052789\n",
      "3: 0.01929911238667816\n",
      "4: 0.06729488533622548\n",
      "5: 0.515399722585458\n",
      "6: 0.018063861886878453\n"
     ]
    }
   ],
   "source": [
    "for k, v in classes.items():\n",
    "    print(f\"{k}: {(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "999a0604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(classes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64feb7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('TM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c16ea8bd56afaa61abb0c90c58be18bc01b827a1a1f02bf5b8eb46947d35325e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
