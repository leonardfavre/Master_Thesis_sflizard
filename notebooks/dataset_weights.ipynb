{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8e0f3a-eea1-4cf4-81e1-d9721276e5f3",
   "metadata": {},
   "source": [
    "# Dataset weights\n",
    "\n",
    "Notebook to get the weight of the different classes present in the dataset.\n",
    "\n",
    "This is computed only in the trainingset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b699a1a4-814f-4a43-ae2a-0b07cfb46c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warnings.py (30): You want to use `gym` which is not installed yet, install it with `pip install gym`.\n"
     ]
    }
   ],
   "source": [
    "from sflizard import LizardDataModule\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855f5368-57ca-44d8-aba8-a0e96194fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=540\n",
    "TRAIN_DATA_PATH=\"../data/Lizard_dataset_extraction/data_final_split_train.pkl\"\n",
    "VALID_DATA_PATH=\"../data/Lizard_dataset_extraction/data_final_split_valid.pkl\"\n",
    "TEST_DATA_PATH=\"../data/Lizard_dataset_extraction/data_final_split_test.pkl\"\n",
    "SEED=303\n",
    "BATCH_SIZE=4\n",
    "N_RAYS = 32\n",
    "\n",
    "ANNOTATION_TARGET = \"stardist_class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "112f85e6-8096-4f4b-99e4-0881765a4259",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m aditional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_rays\u001b[39m\u001b[38;5;124m\"\u001b[39m:N_RAYS}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# create the datamodule\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m dm \u001b[38;5;241m=\u001b[39m \u001b[43mLizardDataModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_DATA_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALID_DATA_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEST_DATA_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannotation_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mANNOTATION_TARGET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43maditional_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maditional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m dm\u001b[38;5;241m.\u001b[39msetup()\n",
      "File \u001b[0;32m~/Frankenstein_junior/Master_Thesis_LeonardFavre/sflizard/data_utils/data_module.py:167\u001b[0m, in \u001b[0;36mLizardDataModule.__init__\u001b[0;34m(self, train_data_path, valid_data_path, test_data_path, annotation_target, batch_size, num_workers, input_size, seed, aditional_args)\u001b[0m\n\u001b[1;32m    165\u001b[0m     train_data_p \u001b[39m=\u001b[39m Path(train_data_path)\n\u001b[1;32m    166\u001b[0m     \u001b[39mwith\u001b[39;00m train_data_p\u001b[39m.\u001b[39mopen(\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 167\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m    168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/TM/lib/python3.9/site-packages/pandas/_libs/internals.pyx:575\u001b[0m, in \u001b[0;36mpandas._libs.internals._unpickle_block\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/TM/lib/python3.9/site-packages/pandas/core/internals/blocks.py:2169\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim)\u001b[0m\n\u001b[1;32m   2165\u001b[0m     values \u001b[39m=\u001b[39m maybe_coerce_values(values)\n\u001b[1;32m   2166\u001b[0m     \u001b[39mreturn\u001b[39;00m klass(values, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, placement\u001b[39m=\u001b[39mplacement)\n\u001b[0;32m-> 2169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_block\u001b[39m(values, placement, \u001b[39m*\u001b[39m, ndim: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Block:\n\u001b[1;32m   2170\u001b[0m     \u001b[39m# caller is responsible for ensuring values is NOT a PandasArray\u001b[39;00m\n\u001b[1;32m   2172\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(placement, BlockPlacement):\n\u001b[1;32m   2173\u001b[0m         placement \u001b[39m=\u001b[39m BlockPlacement(placement)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aditional_args={\"n_rays\":N_RAYS}\n",
    "\n",
    "# create the datamodule\n",
    "dm = LizardDataModule(\n",
    "    train_data_path=TRAIN_DATA_PATH,\n",
    "    valid_data_path=VALID_DATA_PATH,\n",
    "    test_data_path=TEST_DATA_PATH,\n",
    "    annotation_target=ANNOTATION_TARGET,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers = 1,\n",
    "    input_size=IMG_SIZE,\n",
    "    seed=SEED,\n",
    "    aditional_args=aditional_args,\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4990692",
   "metadata": {},
   "source": [
    "## class map in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd87b71-65ba-4f0f-9b20-2c003f1c18e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744/744 [21:30<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "classes_representation = {}\n",
    "for i in range(7):\n",
    "    classes_representation[i] = 0\n",
    "train_iter = iter(dm.train_dataloader())\n",
    "for b in tqdm(range(len(train_iter))):\n",
    "    image, obj_probabilities, distances, classes = next(train_iter)\n",
    "    for i in range(len(image)):\n",
    "        class_map = torch.flatten(classes[i].int())\n",
    "        occurences = torch.bincount(class_map)\n",
    "        for o in range(len(occurences)):\n",
    "            classes_representation[o] += occurences[o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b41534-0d6a-4dc6-88c8-71c0c54229be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor(730841977), 1: tensor(1233446), 2: tensor(86053998), 3: tensor(15836149), 4: tensor(5157280), 5: tensor(1065106), 6: tensor(27613644)}\n"
     ]
    }
   ],
   "source": [
    "print(classes_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc09dddb-5101-4663-8941-e9fe629f1494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8421763419196278, 1: 0.0014213456163252062, 2: 0.09916321656931723, 3: 0.01824858239486998, 4: 0.005942925203180082, 5: 0.001227361184860687, 6: 0.03182022711181911}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for c in classes_representation.keys():\n",
    "    classes_representation[c] = classes_representation[c].item()\n",
    "    total += classes_representation[c]\n",
    "for c in classes_representation.keys():\n",
    "    classes_representation[c] /= total\n",
    "print(classes_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ba2e3d-f5eb-4de5-9356-55c4d4393212",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d779089-8d0f-438c-9c2e-8ee85bcd199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{0: 0.8421763419196278, 1: 0.0014213456163252062, 2: 0.09916321656931723, 3: 0.01824858239486998, 4: 0.005942925203180082, 5: 0.001227361184860687, 6: 0.03182022711181911}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97847a6b",
   "metadata": {},
   "source": [
    "## HoverNet Graph class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf42fc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2976it [10:25,  4.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "\n",
    "true_dir = \"../data/Lizard_dataset_split/patches/Lizard_Labels_train/\"\n",
    "\n",
    "file_list = glob.glob(\"%s/*mat\" % (true_dir))\n",
    "\n",
    "classes = {}\n",
    "for i in range(7):\n",
    "    classes[i] = 0\n",
    "for idx, file in tqdm(enumerate(file_list)):\n",
    "    mat = sio.loadmat(file)\n",
    "    for i in range(len(mat[\"classes\"])):\n",
    "        classes[mat[\"classes\"][i][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4255506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.0\n",
      "1: 0.0015289419440833998\n",
      "2: 3.543263598039262e-05\n",
      "3: 7.946214852753756e-05\n",
      "4: 0.0002770799022561251\n",
      "5: 0.0021221063687575435\n",
      "6: 7.437612919581149e-05\n"
     ]
    }
   ],
   "source": [
    "class_bp = classes.copy()\n",
    "\n",
    "sum_c = sum(classes.values())\n",
    "for k, v in classes.items():\n",
    "    if k == 0:\n",
    "        classes[k] = 0\n",
    "    else:\n",
    "        classes[k] = 1/(v/sum_c)\n",
    "\n",
    "sum_c = sum(classes.values())\n",
    "for k, v in classes.items():\n",
    "    classes[k] = v/sum_c\n",
    "\n",
    "for k, v in classes.items():\n",
    "    print(f\"{k}: {(v/sum_c)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fa1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.0\n",
      "1: 0.3713368309107073\n",
      "2: 0.008605586894052789\n",
      "3: 0.01929911238667816\n",
      "4: 0.06729488533622548\n",
      "5: 0.515399722585458\n",
      "6: 0.018063861886878453\n"
     ]
    }
   ],
   "source": [
    "for k, v in classes.items():\n",
    "    print(f\"{k}: {(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "999a0604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(classes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64feb7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    0: 0.0,\n",
    "    1: 0.3713368309107073,\n",
    "    2: 0.008605586894052789,\n",
    "    3: 0.01929911238667816,\n",
    "    4: 0.06729488533622548,\n",
    "    5: 0.515399722585458,\n",
    "    6: 0.018063861886878453,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb7553",
   "metadata": {},
   "source": [
    "## Report cell count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f383b93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2941it [03:19, 14.71it/s]\n",
      "453it [00:30, 15.04it/s]\n",
      "349it [00:23, 14.96it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "# splited dataset\n",
    "\n",
    "classes = {\n",
    "    \"train\": {},\n",
    "    \"valid\": {},\n",
    "    \"test\": {},\n",
    "}\n",
    "for c in classes.keys():\n",
    "    true_dir = f\"../data/Lizard_dataset_split/patches/Lizard_Labels_{c}/\"\n",
    "    file_list = glob.glob(\"%s/*mat\" % (true_dir))\n",
    "    for i in range(7):\n",
    "        classes[c][i] = 0\n",
    "    for idx, file in tqdm(enumerate(file_list)):\n",
    "        mat = sio.loadmat(file)\n",
    "        for i in range(len(mat[\"classes\"])):\n",
    "            classes[c][mat[\"classes\"][i][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cba988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 15398, 2: 664434, 3: 296275, 4: 84967, 5: 11094, 6: 316535}\n",
      "0 & 15398 & 664434 & 296275 & 84967 & 11094 & 316535 & \n",
      "{0: 0, 1: 3619, 2: 65409, 3: 18573, 4: 4009, 5: 682, 6: 44961}\n",
      "0 & 3619 & 65409 & 18573 & 4009 & 682 & 44961 & \n",
      "{0: 0, 1: 705, 2: 86274, 3: 59580, 4: 13853, 5: 1784, 6: 39161}\n",
      "0 & 705 & 86274 & 59580 & 13853 & 1784 & 39161 & \n"
     ]
    }
   ],
   "source": [
    "for c in classes.keys():\n",
    "    print(classes[c])\n",
    "    print(\"\".join([f\"{cc} & \" for cc in classes[c].values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7023feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train\n",
      "1388703\n",
      "0.0\n",
      "0.011088044023812147\n",
      "0.47845651662018446\n",
      "0.2133465543028279\n",
      "0.061184428923967187\n",
      "0.007988749214194828\n",
      "0.2279357069150135\n",
      "\n",
      "valid\n",
      "137253\n",
      "0.0\n",
      "0.026367365376348786\n",
      "0.47655788944503946\n",
      "0.1353194465694739\n",
      "0.02920883332240461\n",
      "0.004968925997974543\n",
      "0.3275775392887587\n",
      "\n",
      "test\n",
      "201357\n",
      "0.0\n",
      "0.0035012440590592828\n",
      "0.4284628793635185\n",
      "0.2958923702677334\n",
      "0.06879820418460744\n",
      "0.00885988567569044\n",
      "0.19448541644939088\n"
     ]
    }
   ],
   "source": [
    "for c in classes.keys():\n",
    "    print(\"\\n\"+c)\n",
    "    sum_c = sum(classes[c].values())\n",
    "    print(sum_c)\n",
    "    for k, v in classes[c].items():\n",
    "        print(v/sum_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b856b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210372\n",
      "92238\n",
      "24861\n",
      "4116\n",
      "2979\n",
      "97347\n"
     ]
    }
   ],
   "source": [
    "print(244563 - 34191)\n",
    "print(101413 - 9175)\n",
    "print(28466 - 3605)\n",
    "print(4824 - 708)\n",
    "print(3604 - 625)\n",
    "print(112309 - 14962)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21597eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727313\n",
      "{0: 0, 1: 19722, 2: 816117, 3: 374428, 4: 102829, 5: 13560, 6: 400657}\n"
     ]
    }
   ],
   "source": [
    "sum_tot = 0\n",
    "sums = {\n",
    "    0:0,\n",
    "    1:0,\n",
    "    2:0,\n",
    "    3:0,\n",
    "    4:0,\n",
    "    5:0,\n",
    "    6:0,\n",
    "}\n",
    "for c in classes.keys():\n",
    "    sum_tot += sum(classes[c].values())\n",
    "    for k, v in classes[c].items():\n",
    "        sums[k] += v\n",
    "\n",
    "print(sum_tot)\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ad175e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1727313"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1388703+137253 + 201357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7b954a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8039672022383899\n",
      "0.07946041047569259\n",
      "0.1165723872859175\n"
     ]
    }
   ],
   "source": [
    "print(1388703/1727313)\n",
    "print(137253/1727313)\n",
    "print(201357/1727313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81508a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('TM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c16ea8bd56afaa61abb0c90c58be18bc01b827a1a1f02bf5b8eb46947d35325e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
